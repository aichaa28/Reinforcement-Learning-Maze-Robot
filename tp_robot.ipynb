{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_m05WAR2vyiL"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def generate_grid(size):\n",
        "    grid = np.zeros((size, size))\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            if random.random() < 0.3:\n",
        "                grid[i, j] = -10\n",
        "    # Choisir au hasard l'emplacement du 100\n",
        "    x = random.randint(0, size - 1)\n",
        "    y = random.randint(0, size - 1)\n",
        "    grid[x, y] = 100\n",
        "    return grid\n",
        "\n",
        "def plot_grid(canvas, grid, robot_pos):\n",
        "    canvas.delete(\"all\")\n",
        "    for i in range(len(grid)):\n",
        "        for j in range(len(grid[0])):\n",
        "            x0, y0 = j * 50, i * 50\n",
        "            x1, y1 = x0 + 50, y0 + 50\n",
        "            color = \"white\"\n",
        "            if (i, j) == robot_pos:  # Position du robot\n",
        "                color = \"red\"\n",
        "            elif grid[i, j] == -10:  # Mur\n",
        "                color = \"blue\"\n",
        "            elif grid[i, j] == 100:  # Sortie\n",
        "                color = \"green\"\n",
        "            canvas.create_rectangle(x0, y0, x1, y1, fill=color)\n",
        "    canvas.update()\n",
        "\n",
        "def choose_action(state, epsilon, Q):\n",
        "    if random.random() < epsilon:\n",
        "        return random.choice([0, 1, 2, 3,4,5,6,7])  # Exploration aléatoire\n",
        "    else:\n",
        "        return np.argmax(Q[state[0], state[1]])  # Exploitation de la table Q\n",
        "\n",
        "def get_new_state(state, action, size):\n",
        "    i, j = state\n",
        "    new_i, new_j = i, j\n",
        "    if action == 0 and i > 0:\n",
        "        new_i = i - 1  # Move up\n",
        "    elif action == 1 and i < size - 1:\n",
        "        new_i = i + 1  # Move down\n",
        "    elif action == 2 and j > 0:\n",
        "        new_j = j - 1  # Move left\n",
        "    elif action == 3 and j < size - 1:\n",
        "        new_j = j + 1  # Move right\n",
        "    elif action == 4 and i > 0 and j > 0:\n",
        "        new_i, new_j = i - 1, j - 1  # Move up-left diagonally\n",
        "    elif action == 5 and i > 0 and j < size - 1:\n",
        "        new_i, new_j = i - 1, j + 1  # Move up-right diagonally\n",
        "    elif action == 6 and i < size - 1 and j > 0:\n",
        "        new_i, new_j = i + 1, j - 1  # Move down-left diagonally\n",
        "    elif action == 7 and i < size - 1 and j < size - 1:\n",
        "        new_i, new_j = i + 1, j + 1  # Move down-right diagonally\n",
        "    if 0 <= new_i < size and 0 <= new_j < size:  # Check if the new state is within the grid boundaries\n",
        "        return (new_i, new_j)\n",
        "    return state\n",
        "\n",
        "\n",
        "def Q_learning(canvas, epsilon, gamma, alpha, episodes, size,grid):\n",
        "    Q = np.zeros((size, size, 8))\n",
        "    robot_pos = (0, 0)\n",
        "    for _ in tqdm(range(episodes)):\n",
        "        state = (0, 0)\n",
        "        reward=0\n",
        "        grid2 = np.copy(grid)\n",
        "        while reward != 100:  # Tant que l'objectif n'est pas atteint\n",
        "            action = choose_action(state, epsilon, Q)\n",
        "            new_state = get_new_state(state, action, size)\n",
        "            reward=grid2[new_state[0]][new_state[1]]\n",
        "            if reward==0:\n",
        "                grid2[new_state[0]][new_state[1]]=-1\n",
        "            best_future_reward = np.max(Q[new_state[0], new_state[1]])\n",
        "            Q[state[0], state[1], action] += alpha * (reward + gamma * best_future_reward - Q[state[0], state[1], action])\n",
        "            state = new_state\n",
        "            robot_pos = state\n",
        "            plot_grid(canvas, grid, robot_pos)\n",
        "              # Pause pour visualiser l'apprentissage\n",
        "    return Q\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_grid(size):\n",
        "    grid = np.full((size, size), -1)\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            if random.random() < 0.3:\n",
        "                grid[i, j] = -10\n",
        "    # Choisir au hasard l'emplacement du 100\n",
        "    x = random.randint(0, size - 1)\n",
        "    y = random.randint(0, size - 1)\n",
        "    grid[x, y] = 100\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_grid1(grid):\n",
        "    root = tk.Tk()\n",
        "    root.title(\"Grid Representation\")\n",
        "    \n",
        "    rows = len(grid)\n",
        "    cols = len(grid[0])\n",
        "    \n",
        "    cell_width = 50\n",
        "    cell_height = 50\n",
        "    \n",
        "    canvas = tk.Canvas(root, width=cols * cell_width, height=rows * cell_height)\n",
        "    canvas.pack()\n",
        "    \n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            x0, y0 = j * cell_width, i * cell_height\n",
        "            x1, y1 = x0 + cell_width, y0 + cell_height\n",
        "            color = 'white' if grid[i][j] == -1 else 'blue' if grid[i][j] == -10 else 'green'\n",
        "            canvas.create_rectangle(x0, y0, x1, y1, fill=color, outline='black')\n",
        "    \n",
        "    root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "epsilon = 0.1\n",
        "gamma = 0.9\n",
        "alpha = 0.1\n",
        "episodes = 1000\n",
        "size = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Génération de la grille\n",
        "grid = generate_grid(size)\n",
        "plot_grid1(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_grid1(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 107/1000 [14:46<2:03:18,  8.29s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[47], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m canvas\u001b[38;5;241m.\u001b[39mpack()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Apprentissage Q-Learning\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m Matrice_Q\u001b[38;5;241m=\u001b[39m\u001b[43mQ_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Lancement de la boucle principale tkinter\u001b[39;00m\n\u001b[0;32m     13\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n",
            "Cell \u001b[1;32mIn[36], line 15\u001b[0m, in \u001b[0;36mQ_learning\u001b[1;34m(canvas, epsilon, gamma, alpha, episodes, size, grid)\u001b[0m\n\u001b[0;32m     13\u001b[0m         state \u001b[38;5;241m=\u001b[39m new_state\n\u001b[0;32m     14\u001b[0m         robot_pos \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m---> 15\u001b[0m         \u001b[43mplot_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobot_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m           \u001b[38;5;66;03m# Pause pour visualiser l'apprentissage\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Q\n",
            "Cell \u001b[1;32mIn[4], line 33\u001b[0m, in \u001b[0;36mplot_grid\u001b[1;34m(canvas, grid, robot_pos)\u001b[0m\n\u001b[0;32m     31\u001b[0m             color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m         canvas\u001b[38;5;241m.\u001b[39mcreate_rectangle(x0, y0, x1, y1, fill\u001b[38;5;241m=\u001b[39mcolor)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\tkinter\\__init__.py:1370\u001b[0m, in \u001b[0;36mMisc.update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1369\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Enter event loop until all pending events have been processed by Tcl.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1370\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Initialisation de la fenêtre tkinter\n",
        "root = tk.Tk()\n",
        "root.title(\"Q-Learning Robot\")\n",
        "\n",
        "# Création du canevas\n",
        "canvas = tk.Canvas(root, width=size * 50, height=size * 50)\n",
        "canvas.pack()\n",
        "\n",
        "# Apprentissage Q-Learning\n",
        "Matrice_Q=Q_learning(canvas, epsilon, gamma, alpha, episodes, size,grid)\n",
        "\n",
        "# Lancement de la boucle principale tkinter\n",
        "root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0.   0.   0. -10. -10.   0. -10. -10.   0.   0. -10.   0. -10.   0.\n",
            "    0.   0. -10. -10.   0. -10.]\n",
            " [-10.   0. -10.   0.   0.   0.   0.   0.   0. -10. -10.   0.   0. -10.\n",
            "  -10.   0. -10. -10.   0.   0.]\n",
            " [-10.   0.   0. -10. -10.   0. -10.   0. -10. -10.   0.   0. -10.   0.\n",
            "  -10.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   0.   0. -10.   0.   0.   0.   0. -10.   0. -10.   0.\n",
            "    0.   0. -10.   0.   0. -10.]\n",
            " [  0.   0. -10.   0.   0.   0.   0.   0.   0.   0. -10. -10.   0.   0.\n",
            "    0.   0. -10. -10. -10.   0.]\n",
            " [  0.   0.   0.   0. -10.   0.   0.   0. -10.   0. -10.   0.   0.   0.\n",
            "    0. -10.   0.   0.   0. -10.]\n",
            " [  0. -10.   0.   0.   0.   0.   0.   0. -10.   0. -10.   0. -10.   0.\n",
            "  -10.   0. -10.   0.   0. -10.]\n",
            " [  0.   0.   0.   0. -10. -10. -10.   0. -10.   0.   0.   0. -10.   0.\n",
            "    0. -10. -10.   0.   0. -10.]\n",
            " [  0.   0. -10. -10.   0.   0.   0.   0. -10.   0.   0.   0.   0.   0.\n",
            "  -10. -10.   0. -10.   0.   0.]\n",
            " [  0.   0.   0.   0. -10.   0. -10.   0.   0.   0. -10.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0. -10.   0.   0.   0.   0.   0. -10. -10.   0. -10.   0.   0.\n",
            "  -10.   0.   0.   0.   0.   0.]\n",
            " [-10.   0. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    0. -10.   0.   0.   0.   0.]\n",
            " [  0.   0. -10.   0.   0.   0.   0.   0.   0.   0. -10. -10. -10.   0.\n",
            "    0. -10.   0. 100.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0. -10.   0.   0. -10. -10. -10.   0.   0.\n",
            "    0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0. -10. -10.   0. -10. -10.   0. -10.   0.   0.   0.   0. -10.\n",
            "    0.   0. -10.   0.   0. -10.]\n",
            " [  0.   0.   0.   0.   0.   0. -10. -10.   0. -10. -10.   0.   0.   0.\n",
            "    0.   0.   0.   0.   0. -10.]\n",
            " [  0. -10. -10.   0. -10. -10.   0.   0.   0.   0. -10.   0.   0. -10.\n",
            "  -10.   0.   0.   0.   0. -10.]\n",
            " [  0.   0.   0.   0.   0.   0.   0. -10.   0. -10.   0.   0. -10.   0.\n",
            "    0.   0. -10. -10.   0.   0.]\n",
            " [  0. -10.   0. -10.   0.   0.   0.   0.   0. -10.   0. -10.   0. -10.\n",
            "  -10. -10. -10.   0. -10.   0.]\n",
            " [-10.   0. -10. -10.   0.   0.   0. -10. -10. -10.   0.   0.   0.   0.\n",
            "    0.   0.   0.   0. -10. -10.]]\n"
          ]
        }
      ],
      "source": [
        "print(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[ 3.58788141 -5.76703351  4.00409755 ...  4.50580789  3.39927275\n",
            "    6.87165763]\n",
            "  [ 4.49151655  2.59257828  2.83623097 ...  2.2521479  -4.99988255\n",
            "   -5.44944833]\n",
            "  [ 5.92166485 -5.82638309  3.03000834 ...  3.83525763  0.44372808\n",
            "    9.59411554]\n",
            "  ...\n",
            "  [-1.         -1.         -1.         ... -1.         -1.\n",
            "    0.        ]\n",
            "  [-0.58519851 -0.63916272 -1.         ... -0.58367986 -1.\n",
            "   -0.62150605]\n",
            "  [-1.         -0.32185359 -0.22467621 ... -1.         -0.22456359\n",
            "   -1.        ]]\n",
            "\n",
            " [[ 5.517551   -1.         -1.42668476 ... -0.35895547 -1.\n",
            "   -0.27829489]\n",
            "  [ 7.67611337  0.92118222 -5.78757459 ...  4.97078597 -7.11777673\n",
            "    3.02099579]\n",
            "  [-0.27130091  0.41158899  5.59612922 ... -1.26117965 -0.02880391\n",
            "   -1.00238172]\n",
            "  ...\n",
            "  [-1.         -0.216658   -1.9        ... -0.109      -0.109\n",
            "   -0.109     ]\n",
            "  [-0.4000995  -0.48186172 -1.9        ... -1.90981    -0.40918859\n",
            "   -0.4806451 ]\n",
            "  [-3.465739   -0.47387512 -0.47385658 ... -0.4900995  -0.48192109\n",
            "   -0.4900995 ]]\n",
            "\n",
            " [[-1.         -0.33212492 -1.9        ...  3.75599279 -1.\n",
            "   -0.27364904]\n",
            "  [-0.77411023 -0.76751089 -4.12911006 ... -1.         -0.77614757\n",
            "   -0.76079226]\n",
            "  [-2.22255496 -0.74587421 -0.75451103 ... -0.76714034 -0.79095298\n",
            "   11.02951857]\n",
            "  ...\n",
            "  [-1.         -0.48252499 -0.48380735 ... -0.3933109  -1.9\n",
            "   -0.4830353 ]\n",
            "  [-0.38794051 -0.4668563  -0.38957082 ... -0.41320779 -0.48200923\n",
            "   -1.909     ]\n",
            "  [-0.48217738 -1.909      -0.47161337 ... -0.3940399  -0.47940369\n",
            "   -0.3940399 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.69700177 -0.72488245 -0.67791624 ... -1.         -0.67934652\n",
            "   -1.9       ]\n",
            "  [-1.         -1.         -0.58391479 ... -1.         -0.60906797\n",
            "   -0.61384018]\n",
            "  [-1.909      -0.58500189 -0.65394666 ... -0.6468971  -1.\n",
            "   -1.        ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [-0.1         0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[-0.74760843 -1.         -0.67723686 ... -0.64521686 -0.67774259\n",
            "   -0.73388368]\n",
            "  [-0.12649585 -0.1        -0.199      ... -0.1        -1.\n",
            "   -1.        ]\n",
            "  [-0.5527859  -2.71       -1.         ... -0.554066   -0.53057803\n",
            "   -1.        ]\n",
            "  ...\n",
            "  [-1.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[-0.1        -1.         -1.         ... -1.          0.\n",
            "    0.        ]\n",
            "  [-3.448      -0.67934652 -1.         ... -0.60671247 -0.67934652\n",
            "   -0.67934652]\n",
            "  [-0.2225629  -1.         -0.1        ... -1.         -1.\n",
            "   -1.        ]\n",
            "  ...\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]\n",
            "  [ 0.          0.          0.         ...  0.          0.\n",
            "    0.        ]]]\n"
          ]
        }
      ],
      "source": [
        "print(Matrice_Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(20, 20)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_optimal_path(Q):\n",
        "    size=grid.shape[0]\n",
        "    optimal_path=[]\n",
        "    pos=(4,0)\n",
        "    while (pos not in optimal_path):\n",
        "        optimal_path.append(pos)\n",
        "        action=np.argmax(Q[pos[0], pos[1]])\n",
        "        pos = get_new_state(pos, action, size)\n",
        "    return optimal_path\n",
        "        \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_path=find_optimal_path(Matrice_Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_grid_with_path(grid, optimal_path):\n",
        "    root = tk.Tk()\n",
        "    root.title(\"Grid Representation\")\n",
        "\n",
        "    rows = len(grid)\n",
        "    cols = len(grid[0])\n",
        "\n",
        "    cell_width = 50\n",
        "    cell_height = 50\n",
        "\n",
        "    canvas = tk.Canvas(root, width=cols * cell_width, height=rows * cell_height)\n",
        "    canvas.pack()\n",
        "\n",
        "    # Dessiner la grille en premier\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            x0, y0 = j * cell_width, i * cell_height\n",
        "            x1, y1 = x0 + cell_width, y0 + cell_height\n",
        "            color = 'white' if grid[i][j] == -1 else 'blue' if grid[i][j] == -10 else 'green'\n",
        "            canvas.create_rectangle(x0, y0, x1, y1, fill=color, outline='black')\n",
        "\n",
        "    # Dessiner ensuite le chemin optimal avec des ronds rouges\n",
        "    for pos in optimal_path:\n",
        "        x0, y0 = pos[1] * cell_width + cell_width / 4, pos[0] * cell_height + cell_height / 4\n",
        "        x1, y1 = x0 + cell_width / 2, y0 + cell_height / 2\n",
        "        canvas.create_oval(x0, y0, x1, y1, fill='red')\n",
        "\n",
        "    root.mainloop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_grid_with_path(grid,optimal_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "size=30\n",
        "grid = generate_grid(size)\n",
        "plot_grid1(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [30:40<00:00,  1.84s/it] \n"
          ]
        }
      ],
      "source": [
        "# Initialisation de la fenêtre tkinter\n",
        "root = tk.Tk()\n",
        "root.title(\"Q-Learning Robot\")\n",
        "\n",
        "# Création du canevas\n",
        "canvas = tk.Canvas(root, width=size * 50, height=size * 50)\n",
        "canvas.pack()\n",
        "\n",
        "# Apprentissage Q-Learning\n",
        "Matrice_Q=Q_learning(canvas, epsilon, gamma, alpha, episodes, size,grid)\n",
        "\n",
        "# Lancement de la boucle principale tkinter\n",
        "root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_path=find_optimal_path(Matrice_Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_grid_with_path(grid,optimal_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Q_learning(canvas, epsilon, gamma, alpha, episodes, size,grid):\n",
        "    Q = np.zeros((size, size, 8))\n",
        "    robot_pos = (0, 0)\n",
        "    for _ in tqdm(range(episodes)):\n",
        "        state = (4,0)\n",
        "        reward=0\n",
        "        while reward != 100:  # Tant que l'objectif n'est pas atteint\n",
        "            action = choose_action(state, epsilon, Q)\n",
        "            new_state = get_new_state(state, action, size)\n",
        "            reward=grid[new_state[0]][new_state[1]]\n",
        "            best_future_reward = np.max(Q[new_state[0], new_state[1]])\n",
        "            Q[state[0], state[1], action] += alpha * (reward + gamma * best_future_reward - Q[state[0], state[1], action])\n",
        "            state = new_state\n",
        "            robot_pos = state\n",
        "            plot_grid(canvas, grid, robot_pos)\n",
        "              # Pause pour visualiser l'apprentissage\n",
        "    return Q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid=[[-1,-1,-1,-1,-1,-10,-1,-1,-1,-1],\n",
        "      [-1,-1,-10,-10,-1,-10,-1,-1,-1,-1],\n",
        "      [-1,-1,-1,-10,-1,-10,-1,-10,-1,-1],\n",
        "      [-1,-1,-1,-10,-1,-1,-1,-10,-1,-1],\n",
        "      [-1,-1,-1,-10,-10,-1,-1,-10,-1,100],\n",
        "      [-1,-1,-1,-1,-10,-1,-1,-10,-1,-1],\n",
        "      [-1,-10,-1,-1,-10,-1,-1,-10,-10,-10],\n",
        "      [-1,-10,-10,-10,-10,-1,-1,-1,-1,-1],\n",
        "      [-1,-1,-1,-1,-1,-1,-10,-1,-1,-1],\n",
        "      [-1,-1,-1,-1,-1,-1,-10,-1,-1,-1]]\n",
        "grid = np.array(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_grid1(grid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "size=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [01:45<00:00,  9.45it/s]\n"
          ]
        }
      ],
      "source": [
        "# Initialisation de la fenêtre tkinter\n",
        "root = tk.Tk()\n",
        "root.title(\"Q-Learning Robot\")\n",
        "\n",
        "# Création du canevas\n",
        "canvas = tk.Canvas(root, width=size * 50, height=size * 50)\n",
        "canvas.pack()\n",
        "\n",
        "# Apprentissage Q-Learning\n",
        "Matrice_Q=Q_learning(canvas, epsilon, gamma, alpha, episodes, size,grid)\n",
        "\n",
        "# Lancement de la boucle principale tkinter\n",
        "root.mainloop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimal_path=find_optimal_path(Matrice_Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_grid_with_path(grid,optimal_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ILfyvarsvXv"
      },
      "source": [
        "Affichage de la grille"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
